差分隐私在隐私数据框架中占据主导地位。研究最为广泛的差分隐私设置称为中心化模型，依靠一个可信任的权威，算法输入用户的原始数据，在输出上加入隐私保护。
在许多场景下，这样的可信权威是不存在的，这成为了分布式差分隐私模型的研究动机。本地模型是研究最充分的一类设定，将隐私保护施加在每一个用户的输出上。尽管本地模型的一个优势在于本地模型具有强隐私保护能力且需要最少的可信任假设，但是必需的噪声有时会相当大。这激励了中间模型的研究，在更多的分布式信任假设下，实现更接近于中心化模型的准确度。其中一种中间方案称为打乱模型，用户将消息发送给打乱者，打乱者随机打乱这些消息然后发送给分析者。隐私保护施加在打乱后的消息上。在这项工作中，我们研究本地和打乱两种模型。

Differential privacy has become a leading framework for private data analysis. The most commonly studied DP setting is the so-called central model whereby a single authority is trusted with running an algorithm on the raw data of the users and the privacy guarantee applies to the algorithm’s output .
In many scenarios, the absence of a clear trusted authority has motivated the study of distributed DP models. The most well-studied such setting is the local model, where the privacy guarantee is enforced at each user’s output. While an advantage of the local model is its very strong privacy guarantees and minimal trust assumptions, the noise that has to be added can sometimes be quite large. This has stimulated the study of intermediate model that seek to achieve accuracy close to the central model while relying on more distributed trust assumptions. One such middle-ground is so-called shuffle model, where the users send messages to a shuffler who randomly shuffles these messages before sending them to the analyzer. The privacy guarantee in enforced on the shuffled messages. We study both the local and the shuffle models in this work.
