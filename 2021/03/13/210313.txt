最后，我们对各种向量位的和𝑘的值比较了LSHRR和LapLSH的效用损失（参见图3）。我们观察到在所有实验中，LSHRR的性能都优于LapLSH，尽管对于较小的𝜖，其性能相近。对于较小的位串长度（𝜅 = 10），较小的距离（𝑑𝜃 = 0.05）和较高的向量尺寸（𝑛= 1000），LSHRR明显优于LapLSH。我们认为这是因为LapLSH需要为输入向量的每个元素添加噪声（即使向量稀疏并且包含许多零元素），并且在高维数据中噪声总量非常大。我们推测，对于高维向量w.r.t，LSHRR在近邻用户（小𝑑𝜃）上的性能将进一步优于LapLSH。

Finally, we compared the utility loss of LSHRR against LapLSH for various vector dimensions and values of 𝑘 (see Figure 3). We observe that LSHRR outperforms LapLSH across all experiments, although performance is comparable for small 𝜖. LSHRR significantly outperforms LapLSH for smaller bitstring length (𝜅 = 10), smaller distance (𝑑𝜃 = 0.05) and higher vector dimensions (𝑛 = 1000). We consider this is because LapLSH needs to add noise for each element of the input vector (even if the vector is sparse and includes many zero elements) and the total amount of noise is very large in high-dimensional data. We conjecture that LSHRR will further outperform LapLSH for much higher dimensional vectors w.r.t. close users (small 𝑑𝜃 ).
