联邦设置特有的三个主要约束使训练高质量模型变得困难。首先，在边缘进行训练时，通信效率是必需的，因为客户端通常会通过慢速连接连接到中心聚合器。其次，客户端必须是无状态的，因为在训练期间没有客户端多次参与训练是常见情形。第三，跨客户端收集的数据通常不是独立的同分布的。例如，在训练智能手机用户键入的下一个词预测模型时，处于不同地理区域的客户端会生成不同分布的数据，但是分布之间存在足够的共性，我们可能仍想训练一个模型。

There are three main constraints unique to the federated setting that make training high-quality models difficult. First, communication-efficiency is a necessity when training on the edge, since clients typically connect to the central aggregator over slow connections. Second, clients must be stateless, since it is often the case that no client participates more than once during all of training. Third, the data collected across clients is typically not independent and identically distributed. For example, when training a next-word prediction model on the typing data of smartphone users, clients located in geographically distinct regions generate data from different distributions, but enough commonality exists between the distributions that we may still want to train a single model.
